# LDA

概率主题模型：隐含狄利克雷分布（Latent Dirichlet Allocation，简称LDA）

理解LDA，可以分为下述5个步骤：

1. 一个函数：gamma函数
2. 四个分布：二项分布、多项分布、beta分布、Dirichlet分布
3. 一个概念和一个理念：共轭先验和贝叶斯框架
4. 两个模型：pLSA、LDA（在本文[第4 部分](http://blog.csdn.net/v_july_v/article/details/41209515#t14)阐述）
5. 一个采样：Gibbs采样

LDA是一种主题模型，它可以将**文档集 中每篇文档的主题以概率分布的形式给出**，从而通过分析一些文档**抽取出它们的主题（分布）出来**后，便可以根据**主题（分布）进行主题聚类或文本分类**。同时，它是一种典型的词袋模型，即一篇文档是由一组词构成，词与词之间没有先后顺序的关系。

此外，**一篇文档可以包含多个主题，文档中每一个词都由其中的一个主题生成。**

反过来，当我们看到一篇文章后，往往喜欢推测这篇文章是如何生成的，我们可能会认为作者先确定这篇文章的几个主题，然后围绕这几个主题遣词造句，表达成文。

所以，LDA就是要干这事：**根据给定的一篇文档，反推其主题分布**。

**人类是根据上述文档生成过程写成了各种各样的文章，现在某小撮人想让计算机利用LDA干一件事：你计算机给我推测分析网络上各篇文章分别都写了些啥主题，且各篇文章中各个主题出现的概率大小（主题分布）是啥**。

在LDA模型中，一篇文档生成的方式如下：

1. 从狄利克雷分布 $$\alpha$$ 中取样生成文档 $$i$$ 的主题分布 $$\theta_{i}$$ 
2. 从主题的多项式分布 $$\theta_{i}$$ 中取样生成文档 $$i$$ 第 $$j$$ 个词的主题 $$z_{i,j}$$ 
3.  从狄利克雷分布 $$\beta$$ 中取样生成主题 $$z_{i,j}$$ 对应的词语分布 $$\phi_{z_{i,j}}$$ 
4.  从词语的多项式分布 $$\phi_{z_{i,j}}$$ 中采样最终生成词语 $$w_{i,j}$$ 

其中，类似**Beta分布是二项式分布的共轭先验概率分布，而狄利克雷分布（Dirichlet分布）是多项式分布的共轭先验概率分布。**

什么又是共轭呢？

轭的意思是束缚、控制，共轭从字面上理解，则是共同约束，或互相约束。

**在贝叶斯概率理论中，如果后验概率P\(θ\|x\)和先验概率p\(θ\)满足同样的分布律，那么，先验分布和后验分布被叫做共轭分布，同时，先验分布叫做似然函数的共轭先验分布**。

                                         **先验分布**![](https://img-blog.csdn.net/20141110214925523) **+ 样本信息**![](https://img-blog.csdn.net/20141110211153578) ****![](https://img-blog.csdn.net/20141110190250086) **后验分布**![](https://img-blog.csdn.net/20141110215058639)

![](../../.gitbook/assets/image%20%2822%29.png)

 针对于这种**观测到的数据符合多项分布，参数的先验分布和后验分布都是Dirichlet 分布**的情况，**就是Dirichlet-Multinomial 共轭**。换言之，至此已经证明了Dirichlet分布的确就是多项式分布的共轭先验概率分布。

![](../../.gitbook/assets/image.png)

为了方便描述，首先定义一些变量：

* ![](https://img-blog.csdn.net/20141118232053295)表示词，![](https://img-blog.csdn.net/20141118232219439)表示所有单词的个数（固定值）
* ![](https://img-blog.csdn.net/20141118232105500)表示主题，![](https://img-blog.csdn.net/20141118232243400)是主题的个数（预先给定，固定值）
* ![](https://img-blog.csdn.net/20141118232121329)表示语料库，其中的![](https://img-blog.csdn.net/20141118232236677)是语料库中的文档数（固定值）
* ![](https://img-blog.csdn.net/20141118232113406)表示文档，其中的![](https://img-blog.csdn.net/20141118232228453)表示一个文档中的词数（随机变量）

LDA模型中一篇文档生成的方式是怎样的：

1. 按照先验概率 $$p(d_{i})$$ 选择一篇文档 $$d_{i}$$ 
2. 从狄利克雷分布（即Dirichlet分布） $$\alpha$$ 中取样生成文档 $$d_{i}$$ 的主题分布 $$\theta_{i}$$ ，换言之，主题分布 $$\theta_{i}$$ 由超参数为 $$\alpha$$ 的Dirichlet分布生成 
3. 从主题的多项式分布 $$\theta_{i}$$ 中取样生成文档 $$d_{i}$$ 第 j 个词的主题 $$z_{i,j}$$ 
4. 从狄利克雷分布（即Dirichlet分布） $$\beta$$ 中取样生成主题对应的词语分布 $$\phi_{z_{i,j}}$$ ，换言之，词语分布 $$\phi_{z_{i,j}}$$ 由参数为 $$\beta$$ 的Dirichlet分布生成
5. 从词语的多项式分布中采样最终生成词语 $$w_{i,j}$$ ”

**那PLSA跟LDA的区别在于什么地方呢？区别就在于：**

PLSA中，主题分布和词分布是唯一确定的，能明确的指出主题分布可能就是{教育：0.5，经济：0.3，交通：0.2}，词分布可能就是{大学：0.5，老师：0.3，课程：0.2}。但在LDA中，主题分布和词分布不再唯一确定不变，即无法确切给出。例如主题分布可能是{教育：0.5，经济：0.3，交通：0.2}，也可能是{教育：0.6，经济：0.2，交通：0.2}，到底是哪个我们不再确定（即不知道），因为它是随机的可变化的。但再怎么变化，也依然服从一定的分布，即主题分布跟词分布由Dirichlet先验随机确定。























































